"""
Qwen3 æ¨¡å‹æ¶æ„è¯¦ç»†å›¾ (ASCII é£æ ¼)
åŸºäº transformers åº“ä¸­çš„ modular_qwen3.py å®ç°
"""

qwen3_architecture = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            Qwen3 Model Architecture                        â”‚
â”‚                         Based on Transformer Decoder                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Input Token IDs                               â”‚
â”‚                           vocab_size = 151,936                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Token Embedding                                  â”‚
â”‚                           hidden_size = 4096                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    32x Qwen3DecoderLayer Stack                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      Qwen3DecoderLayer                                 â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚                   Qwen3Attention Block                             â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                                                     â”‚ â”‚ â”‚
â”‚ â”‚ â”‚    Input: [B, L, 4096]                                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                                                         â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€ Q_proj â”€â”€â”€â”€â”€â”€â”                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚        (4096â†’4096)   â”‚                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                      â–¼                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                  Q_norm (RMS)                           â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                      â”‚                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                      â–¼                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚              Reshape: [B,32,L,128]                      â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                      â”‚                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€ K_proj â”€â”€â”€â”€â”€â”€â”¤                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚        (4096â†’4096)   â”‚                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                      â–¼                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                  K_norm (RMS)                           â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                      â”‚                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                      â–¼                                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚              Reshape: [B,32,L,128] â”€â”€â”                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                                      â”‚                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â””â”€â”€â”€â”€â”€â”€â”€ V_proj â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                    (4096â†’4096)                   â”‚                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                           â”‚                      â”‚                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                           â–¼                      â–¼                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                   Reshape: [B,32,L,128]    RoPE(Q,K)               â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                           â”‚                      â”‚                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                  â”‚                                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                  â–¼                                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                     Multi-Head Attention                            â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                   Attention = softmax(QK^T/âˆšd_k)V                   â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                  â”‚                                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                  â–¼                                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                       Sliding Window (å±‚28+)                        â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                         window_size=4096                            â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                  â”‚                                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                  â–¼                                  â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                            O_proj (4096â†’4096)                       â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                  â”‚                                  â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚                                   â”‚                                   â”‚ â”‚
â”‚ â”‚                                   â–¼                                   â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚                    Residual + RMS Norm                             â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                  output = norm(input + attention)                   â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚                                   â”‚                                   â”‚ â”‚
â”‚ â”‚                                   â–¼                                   â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚                        Qwen3MLP Block                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                                                     â”‚ â”‚ â”‚
â”‚ â”‚ â”‚    Input: [B, L, 4096]                                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                                                         â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€ Gate_proj â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚       (4096â†’22016)       â”‚                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                          â–¼                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                     SiLU(gate)                          â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                          â”‚                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â”‚                          â”‚                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚           â””â”€â”€â”€â”€â”€â”€â”€ Up_proj â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€ âŠ— (element-wise multiply) â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                   (4096â†’22016)       â”‚                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                      â”‚                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                      â–¼                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                              Down_proj                              â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                             (22016â†’4096)                            â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                                      â”‚                              â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚                                       â”‚                               â”‚ â”‚
â”‚ â”‚                                       â–¼                               â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚                    Residual + RMS Norm                             â”‚ â”‚ â”‚
â”‚ â”‚ â”‚                  output = norm(input + mlp)                         â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Final RMS Norm                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Language Model Head                                â”‚
â”‚                    Linear: 4096 â†’ vocab_size(151936)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Output Logits                                     â”‚
â”‚                      Vocabulary Distribution                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                               å…³é”®ç‰¹æ€§è¯¦è§£
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”§ Qwen3 ç‹¬æœ‰ç‰¹æ€§:
â”œâ”€â”€ Q/K Normalization: åœ¨ head_dim ç»´åº¦ä¸Šè¿›è¡Œ RMS å½’ä¸€åŒ–
â”œâ”€â”€ æ··åˆæ³¨æ„åŠ›æ¨¡å¼:
â”‚   â”œâ”€â”€ å‰ 28 å±‚: å…¨å±€æ³¨æ„åŠ› (full_attention)
â”‚   â””â”€â”€ å 4 å±‚: æ»‘åŠ¨çª—å£æ³¨æ„åŠ› (sliding_attention, window=4096)
â”œâ”€â”€ ç»§æ‰¿è‡ª Qwen2 æ¶æ„ä½†æœ‰æ”¹è¿›
â””â”€â”€ å…¼å®¹å¤šç§æ³¨æ„åŠ›åç«¯ (eager, flash_attention, sdpa)

ğŸ“ æ¨¡å‹å‚æ•°:
â”œâ”€â”€ è¯æ±‡è¡¨å¤§å°: 151,936
â”œâ”€â”€ éšè—å±‚ç»´åº¦: 4,096
â”œâ”€â”€ ä¸­é—´å±‚ç»´åº¦: 22,016
â”œâ”€â”€ å±‚æ•°: 32
â”œâ”€â”€ æ³¨æ„åŠ›å¤´æ•°: 32
â”œâ”€â”€ å¤´ç»´åº¦: 128
â”œâ”€â”€ æœ€å¤§åºåˆ—é•¿åº¦: 32,768
â”œâ”€â”€ RoPE theta: 10,000
â””â”€â”€ RMS Norm epsilon: 1e-6

ğŸ§® å…³é”®è®¡ç®—å…¬å¼:
â”œâ”€â”€ Attention: softmax(QK^T/âˆšd_k)V
â”œâ”€â”€ Q_norm: RMSNorm(Q) = Q / sqrt(mean(QÂ²) + Îµ)
â”œâ”€â”€ K_norm: RMSNorm(K) = K / sqrt(mean(KÂ²) + Îµ)
â”œâ”€â”€ MLP: Down(SiLU(Gate(x)) âŠ— Up(x))
â””â”€â”€ RoPE: æ—‹è½¬ä½ç½®ç¼–ç åº”ç”¨äº Q å’Œ K

âš¡ æ•°æ®æµç»´åº¦:
â”œâ”€â”€ Input: [batch_size, seq_len] â†’ Embedding â†’ [batch_size, seq_len, 4096]
â”œâ”€â”€ Attention: [B, L, 4096] â†’ [B, 32, L, 128] â†’ [B, L, 4096]
â”œâ”€â”€ MLP: [B, L, 4096] â†’ [B, L, 22016] â†’ [B, L, 4096]
â””â”€â”€ Output: [B, L, 4096] â†’ [B, L, 151936] (logits)

ğŸ”„ ç»§æ‰¿å…³ç³»:
â”œâ”€â”€ Qwen3Config â† PretrainedConfig
â”œâ”€â”€ Qwen3RMSNorm â† Qwen2RMSNorm
â”œâ”€â”€ Qwen3MLP â† GemmaMLP
â”œâ”€â”€ Qwen3Attention â† LlamaAttention (+ Q/K norm)
â”œâ”€â”€ Qwen3DecoderLayer â† Qwen2DecoderLayer
â”œâ”€â”€ Qwen3Model â† Qwen2Model
â””â”€â”€ Qwen3ForCausalLM â† Qwen2ForCausalLM
"""

def save_ascii_diagram():
    """ä¿å­˜ ASCII æ¶æ„å›¾åˆ°æ–‡ä»¶"""
    output_path = '/Users/shenkai/code/transformers-1/qwen3_architecture_ascii.txt'

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(qwen3_architecture)

    print(f"Qwen3 ASCII æ¶æ„å›¾å·²ä¿å­˜åˆ°: {output_path}")
    return output_path

if __name__ == "__main__":
    save_ascii_diagram()
    print("\n" + qwen3_architecture)